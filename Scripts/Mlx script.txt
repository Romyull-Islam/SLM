from mlx_lm import load, generate

model, tokenizer = load("mlx-community/OpenELM-270M")
response = generate(model, tokenizer, prompt="Building a website can be done in 10 simple steps:\nStep 1:", verbose=True)